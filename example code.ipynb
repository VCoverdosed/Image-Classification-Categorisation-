{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bcc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358c9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_keypoints(image, num_keypoints):\n",
    "    keypoints = []\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # 计算每个网格的大小\n",
    "    grid_size_x = width // int(np.sqrt(num_keypoints))\n",
    "    grid_size_y = height // int(np.sqrt(num_keypoints))\n",
    "    \n",
    "    # 在每个网格中选择一个点作为关键点\n",
    "    for i in range(0, width, grid_size_x):\n",
    "        for j in range(0, height, grid_size_y):\n",
    "            x = i + grid_size_x // 2\n",
    "            y = j + grid_size_y // 2\n",
    "            keypoints.append(cv2.KeyPoint(x, y, 10))  # 10是关键点的尺度\n",
    "            \n",
    "            # 如果已经选择了足够多的关键点，则停止\n",
    "            if len(keypoints) == num_keypoints:\n",
    "                return keypoints\n",
    "    \n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784d7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path, num_keypoints):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints = random_keypoints(img, num_keypoints)\n",
    "    keypoints, descriptors = sift.compute(img, keypoints)\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a841b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(train_data_dir, num_clusters, num_keypoints):\n",
    "    # 定义提取特征的函数\n",
    "    def extract_features_from_folder(folder_path, num_keypoints=num_keypoints):\n",
    "        features = []\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            img_features = extract_features(img_path,num_keypoints=num_keypoints)\n",
    "            features.extend(img_features)\n",
    "        return features\n",
    "    \n",
    "    # 遍历每个类别文件夹并提取特征\n",
    "    all_features = []\n",
    "    for class_name in os.listdir(train_data_dir):\n",
    "        class_dir = os.path.join(train_data_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        class_features = extract_features_from_folder(class_dir, num_keypoints=num_keypoints)\n",
    "        all_features.extend(class_features)\n",
    "    \n",
    "    # 将提取的特征转换成特征矩阵\n",
    "    features_matrix = np.array(all_features)\n",
    "    \n",
    "    # 应用K均值算法进行聚类\n",
    "    kmeans = KMeans(n_clusters=num_clusters, n_init='auto')\n",
    "    kmeans.fit(features_matrix)\n",
    "    \n",
    "    # 得到词典，即聚类中心\n",
    "    vocabulary = kmeans.cluster_centers_\n",
    "    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b603dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files_and_integer_labels(base_dir, image_extensions=['.jpg', '.jpeg', '.png', '.gif', '.bmp']):\n",
    "    # Sort folder names case-insensitively and create the mapping\n",
    "    folders = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))], key=lambda x: x.lower())\n",
    "    folder_to_int_label = {folder.lower(): i+1 for i, folder in enumerate(folders)}  # Mapping is lowercase\n",
    "\n",
    "    image_files = []\n",
    "    int_labels = []\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        for extension in image_extensions:\n",
    "            for file in glob.glob(os.path.join(folder_path, '*' + extension)):\n",
    "                image_files.append(file)\n",
    "                # Assign labels using lowercase folder name for consistency\n",
    "                int_labels.append(folder_to_int_label[folder.lower()])\n",
    "    \n",
    "    return image_files, int_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7133dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(image_files, int_labels, vocabulary,num_keypoints):\n",
    "    histograms = []\n",
    "    for image_file, label in zip(image_files, int_labels):\n",
    "        img_features = extract_features(image_file,num_keypoints=num_keypoints)  # 提取图像特征\n",
    "        hist = np.zeros(len(vocabulary))\n",
    "        for feature in img_features:\n",
    "            # 计算图像的直方图\n",
    "            distances = np.linalg.norm(vocabulary - feature, axis=1)\n",
    "            nearest_word_idx = np.argmin(distances)\n",
    "            hist[nearest_word_idx] += 1\n",
    "        histograms.append((hist, label))  # 存储直方图和对应的标签\n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acb066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classify(histograms):\n",
    "    X_train, y_train = zip(*histograms)\n",
    "    \n",
    "    # 初始化高斯核支持向量机分类器\n",
    "    svm_classifier = SVC(kernel='rbf')\n",
    "\n",
    "    # 使用一对所有方法包装分类器\n",
    "    ovr_classifier = OneVsRestClassifier(svm_classifier)\n",
    "\n",
    "    # 在训练集上训练分类器\n",
    "    ovr_classifier.fit(X_train, y_train)\n",
    "    return ovr_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54776cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_dir, num_clusters, num_keypoints):\n",
    "    # 步骤1：构建词汇表\n",
    "    vocabulary = build_vocabulary(train_data_dir, num_clusters=num_clusters,num_keypoints=num_keypoints)\n",
    "    # 步骤2:获取图片文件路径并按字母顺序标签\n",
    "    image_files, int_labels = get_image_files_and_integer_labels(train_data_dir)\n",
    "    # 步骤3：获取视觉单词的直方图\n",
    "    histograms = get_hist(image_files, int_labels, vocabulary,num_keypoints)\n",
    "    # 步骤4:用一对多svm分类器训练\n",
    "    ovr_classifier = svm_classify(histograms)\n",
    "    return ovr_classifier,vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02044582",
   "metadata": {},
   "source": [
    "## 写入train_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4f07501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/users/huangsicheng/Desktop/DSA5203/Assignment3/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e9b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_svm_dir,vocabulary = train(train_data_dir, num_clusters=200, num_keypoints=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ccf99",
   "metadata": {},
   "source": [
    "## 写入test_data_dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2385ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir= \"/users/huangsicheng/Desktop/DSA5203/Assignment3/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "611f0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data_dir, trained_svm_dir, vocabulary,num_keypoints):\n",
    "    # 获取图片文件路径并按字母顺序标签\n",
    "    image_files, int_labels = get_image_files_and_integer_labels(test_data_dir)\n",
    "    histograms = get_hist(image_files, int_labels, vocabulary,num_keypoints)\n",
    "    # 将test_data得到的直方图与标签信息录入X_test与y_test\n",
    "    X_test, y_test = zip(*histograms)\n",
    "    # 使用训练好的模型进行预测\n",
    "    y_predict = trained_svm_dir.predict(X_test)\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_test, y_predict)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f36599cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test(test_data_dir, trained_svm_dir, vocabulary,num_keypoints=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1245acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9793333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686f33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491ccc89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
